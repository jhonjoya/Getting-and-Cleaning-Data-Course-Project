DT[c(2,3)]
DT[,c(2,3)]
{
x =1
y = 2
}
k = {print(10);5}
k
DT[, list(mean(x), sum(z))]
DT[, table(y)]
DT[,w:=z^2]
head(DT)
DT[,{tmp <- (x+z); log2(tmp+5)}]
DT[,m:={tmp <- (x+z); log2(tmp+5)}]
head(DT)
DT[,a:=x>0]
head(DT)
DT[, b:= mean(x+w), by = a]
head(DT)
set.seed(123);
DT <- data.table(x=sample(letters[1:3], 1E5, TRUE))
DT[, .N by=x]
DT[, .N, by=x]
DT <- data.table(x=rep(c("a","b","c"), each = 100), y = rnorm(300))
setkey(DT,x)
DT["a"]
DT["b"]
DT1 <- data.table(x=c('a','a','b','dt1'), y=1:4)
DT2 <- data.table(x=c('a','b','dt2'), z=5:7)
setkey(DT1,x); setkey(DT2,x)
merge(DT1, DT2)
big_df <- data.frame(x=rnorm(1E6), y=rnorm(1E6))
file <- tempfile()
write.table(big_df, file = file, row.names = FALSE, col.names = TRUE, sep = "\t", quote = FALSE)
system.time(fread(file))
system.time(read.table(file, header = TRUE, sep = "\t"))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile = "./datasets/housing-idaho.csv", method = "curl")
dateDownloaded <- date()
housing-idaho <- read.csv('./datasets/housing-idaho.csv')
housing_idaho <- read.csv('./datasets/housing-idaho.csv')
summary(housing_idaho)
str(housing_idaho)
sum(housing_idaho[,housing_idaho$VAL == 24])
sum(housing_idaho[housing_idaho$VAL == 24,])
sum(housing_idaho[,housing_idaho$VAL == 24]$VAL)
sum(housing_idaho[housing_idaho$VAL == 24,]$VAL)
housing_idaho[,housing_idaho$VAL == 24]$VAL
housing_idaho[housing_idaho$VAL == 24,]$VAL
housing_idaho[housing_idaho$VAL == 24,]
head(housing_idaho)
head(housing_idaho[,housing_idaho==18])
head(housing_idaho[housing_idaho==18],)
head(housing_idaho[housing_idaho==18])
head(housing_idaho[housing_idaho$VAL==18],)
head(housing_idaho[,housing_idaho$VAL==18])
head(housing_idaho[housing_idaho$VAL==18])
head(housing_idaho$VAL)
head(housing_idaho[housing_idaho$VAL == 18,])
head(housing_idaho[,housing_idaho$VAL == 18])
housing_idaho[housing_idaho$VAL == 18,]
?sum
sum(housing_idaho[housing_idaho$VAL == 24,]$VAL, na.rm = TRUE)
str(housing_idaho$FES)
?read.xlsx
library(xlsx)
?read.xlsx
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", destfile = "./datasets/natural-gas.xlsx", method = "curl")
dat <- read.xlsx("./datasets/natural-gas.xlsx",sheetIndex = 1, startRow = 18, endRow = 23, colIndex = 7:15)
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
doc <- xmlTreeParse("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", useInternal = TRUE)
doc <- xmlTreeParse("./datasets/getdata_data_restaurants.xml", useInternal = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
xpathSApply(rootNode, "//zipcode", xmlValue)
nrow(xpathSApply(rootNode, "//zipcode", xmlValue) == "21231")
zipcode <- xpathSApply(rootNode, "//zipcode", xmlValue); head(zipcode)
zipcode[zipcode == "21231"]
nrow(zipcode[zipcode == "21231"])
ncol(zipcode[zipcode == "21231"])
?fread
DT <- fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
pwgtp15
DT[,mean(pwgtp15),by=SEX]
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1]); system.time(rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1])
install.packages("RMySQL")
install.packages("RMySQL")
library(RMySQL)
ucscDb <- dbConnect(MySQL(), user="genomep", host="genome-mysql.soe.ucsc.edu")
ucscDb <- dbConnect(MySQL(), user="genomep", password="password", host="genome-mysql.soe.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;"); dbDisconnect(ucscDb);
result
hg19 <- dbConnect(MySQL(), user="genomep", password="password", db="hg19", host="genome-mysql.soe.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query); quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n=10); dbClearResult(query);
dim(affyMisSmall)
dbDisconnect(hg19)
source("http://bioconductor.org/biocLite.R")
install.packages("BiocManager")
biocLite("rhdf5")
library(rhdf5)
install.packages("rhdf5")
BiocManager::install("rhdf5")
library(rhdf5)
library(h5df)
library(rhdf5)
A <- matrix(1:10, nr = 5, nc = 2)
created <- h5createFile("example.h5")
created
created <- h5createGroup("example.h5", "foo")
created <- h5createGroup("example.h5", "baa")
created <- h5createGroup("example.h5", "foo/boobaa")
h5ls("example.h5")
h5write(A, "example.h5", "foo/A")
B <- array(seq(0.1,2.0, by=0.1), dim = c(5,2,2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5", "foo/foobaa/B")
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url,useInternalNodes = T)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url,useInternalNodes = T)
xpathSApply(html, "//title", xmlValue)
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)
library(XML)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html, "//title", xmlValue)
library(XML)
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
file <- download(url)
install.packages("xml2")
?xml2
?xml
?xml_url
library(xml2)
?xml_url
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
file <- xml_url(url)
?download_html
url <- "https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
file <- download_html(url)
html <- htmlTreeParse(file, useInternalNodes=T)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='gsc_rsb_st']", xmlValue)
xpathSApply(html, "//td[@class='gsc_a_c']", xmlValue)
library(httr); html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText = T)
xpathSApply(parsedHtml, "//title", xmlValue)
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg1 = GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user","passwd"))
pg1
names(pg2)
names(pg1)
google <- handle("http://google.com")
pg1 <- GET(handle = google, path = "/")
pg2 <- GET(handle = google, path = "search")
names(pg1)
names(pg2)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "./datasets/acs.csv", method = "curl")
acs <- read.csv('./datasets/acs.csv')
str(acs)
install.packages("sqldf")
sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
sqldf("select pwgtp1 from acs where AGEP < 50")
?sqldf
sqldf("select pwgtp1 from acs where AGEP < 50")
library(RMySQL)
sqldf("select pwgtp1 from acs where AGEP < 50")
?sqldf
library(sqldf)
?sqldf
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "./datasets/acs.csv", method = "curl")
acs <- read.csv('./datasets/acs.csv')
sqldf("select pwgtp1 from acs where AGEP < 50")
options(sqldf.driver = "RMySQL")
sqldf("select pwgtp1 from acs where AGEP < 50")
options(sqldf.driver = "SQLite")
sqldf("select pwgtp1 from acs where AGEP < 50")
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "56b637a5baffac62cad9",
secret = "8e107541ae1791259e9987d544ca568633da2ebf"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "9a1f5b4f8d8e458e2bee",
secret = " 3c560539734513d7d8a2bc8e3c751c41831ac032"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
install.packages("httpuv")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "9a1f5b4f8d8e458e2bee",
secret = " 3c560539734513d7d8a2bc8e3c751c41831ac032"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
req
myapp <- oauth_app("github",
key = "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",
secret = " 3c560539734513d7d8a2bc8e3c751c41831ac032"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
oauth_endpoints("github")
myapp <- oauth_app("github.com", key = "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", secret = " 3c560539734513d7d8a2bc8e3c751c41831ac032")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
?read.fwf
file <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
file <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "./datasets/Fwksst8110.for")
Fwksst8110 <- read.fwf(file, skip = 2)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "./datasets/Fwksst8110.for")
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5), skip = 2)
sum(Fwksst8110[,4])
sum(Fwksst8110[,4], na.rm = T)
sum(Fwksst8110[,5], na.rm = T)
sum(Fwksst8110[,3], na.rm = T)
sum(Fwksst8110[,2], na.rm = T)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5), skip = c(1,2))
sum(Fwksst8110[,4], na.rm = T)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5), skip = 3)
sum(Fwksst8110[,4], na.rm = T)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5), skip = 4)
sum(Fwksst8110[,4], na.rm = T)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10), skip = 4)
sum(Fwksst8110[,4], na.rm = T)
head(Fwksst8110)
sum(Fwksst8110[,8], na.rm = T)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11,12,13,14), skip = 4)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11), skip = 4)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11), sep = "\t", skip = 4)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11), sep = "     ", skip = 4)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11), sep = "", skip = 4)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11))
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11), sep = "\t\t", skip = 4)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11), sep = "\n", skip = 4)
head(Fwksst8110)
Fwksst8110 <- read.fwf("./datasets/Fwksst8110.for", widths = c(1,2,3,4,5,6,7,8,9,10,11), sep = "\t", skip = 4)
sum(Fwksst8110[,4], na.rm = T)
head(Fwksst8110)
Fwksst8110 <- read.fwf(file = url("https://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"), widths = c(12, 7, 4, 9, 4, 9, 4, 9, 4))
head(Fwksst8110)
Fwksst8110 <- read.fwf(file = url("https://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"), widths = c(12, 7, 4, 9, 4, 9, 4, 9, 4), skip = 4)
head(Fwksst8110)
sum(Fwksst8110[,4], na.rm = T)
sum(Fwksst8110[,5], na.rm = T)
sum(Fwksst8110[,3], na.rm = T)
tail(Fwksst8110)
Fwksst8110[1322,]
sum(Fwksst8110[1:1322,4], na.rm = T)
set.seed(13435)
X <- data.frame("var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
X[,1]
X[,"var1"]
X[1:2,"var2"]
X[(X$var1 <= 3 & X$var3 > 11),]
install.packages("Hmisc")
install.packages("jpeg")
install.packages("latticeExtra")
install.packages("lattice")
install.packages("Hmisc")
install.packages("latticeExtra")
install.packages("jpeg")
install.packages("jpeglib")
install.packages("Hmisc")
install.packages("jpeg","latticeExtra")
install.packages("jpeg","latticeExtra")
install.packages("latticeExtra")
install.packages("Hmisc")
library(dplyr)
df1 <- data.frame(id = sample(1:10), x = rnorm(10))
df2 <- data.frame(id = sample(1:10), y = rnorm(10))
arrange(join(df1,df2),id)
library(plyr)
arrange(join(df1,df2),id)
df1 <- data.frame(id = sample(1:10), x = rnorm(10))
df2 <- data.frame(id = sample(1:10), y = rnorm(10))
df3 <- data.frame(id = sample(1:10), x = rnorm(10))
dfList <- list(df1, df2, df3)
join_all(dfList)
df3 <- data.frame(id = sample(1:10), z = rnorm(10))
dfList <- list(df1, df2, df3)
join_all(dfList)
library(swirl)
swirl()
swirl()
swirl()
swirl()
swirl()
install_course("Getting_and_Cleaning_Data")
swirl()
swirl()
install.packages("dplyr")
install.packages("dplyr")
swirl()
library(swirl)
swirl()
library(swirl)
swirl()
swirl()
swirl()
swirl()
read.csv(path2csv, stringsAsFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r:arch:country)
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
select(cran, -5:20)
size(-5:20)
size(cran,-5:20)
-5:20
(-5:20)
-(5:20)
select(cran, -(1:size(cran)))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.1.1", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran, ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran2, c("ip_id", "package", "size"))
cran3 <- select(cran, c("ip_id", "package", "size"))
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_m = size / 2^20)
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
summarize(by_package, mean(size))
submit()
tbl; pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
cran %>%
select(ip_id, country, package, size) %>%
print
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex","class"))
submit()
students3
?gather
submit()
?spread
submit()
submit()
library(readr)
parse_number("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
passed %>% mutate(passed = "passed")
passed <- passed %>% mutate(passed = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
?bind_rows
bind_rows(passed, failed)
sat
?select
?separate
submit()
?group_by
submit()
library(dplyr)
library(data.table)
features_names <- read.table("UCI HAR Dataset/features.txt", header = F)
features_names <- read.table("UCI HAR Dataset/features.txt", header = F)
setwd("~/Source/Getting-and-Cleaning-Data-Course-Project")
features_names <- read.table("UCI HAR Dataset/features.txt", header = F)
activity_levels <- read.table("UCI HAR Dataset/activity_labels.txt", header = F)
features_names$V2 <- gsub("tBody","time.domain.body", features_names$V2)
features_names$V2 <- gsub("tGravity","time.domain.gravity",features_names$V2)
features_names$V2 <- gsub("fBody","FastFourierTransform.domain.body",features_names$V2)
features_names$V2 <- gsub("fGravity","FastFourierTransform.domain.gravity",features_names$V2)
features_names$V2 <- gsub("Acc",".accelerometer",features_names$V2)
features_names$V2 <- gsub("Gyro",".gyroscope",features_names$V2)
features_names$V2 <- gsub("Jerk",".JerkSignal",features_names$V2)
features_names$V2 <- gsub("Mag",".EuclideanNormDimensionalMagnitude",features_names$V2)
features_names$V2 <- gsub("mean()", "MeanValue",features_names$V2)
features_names$V2 <- gsub("std()", "StandardDeviation",features_names$V2)
features_names$V2 <- gsub("mad()", "MedianAbsoluteDeviation",features_names$V2)
features_names$V2 <- gsub("max()", "LargestValueArray",features_names$V2)
features_names$V2 <- gsub("min()", "SmallestValueArray",features_names$V2)
features_names$V2 <- gsub("sma()", "SignalMagnitudeArea",features_names$V2)
features_names$V2 <- gsub("energy()", "EnergyMeasure",features_names$V2)
features_names$V2 <- gsub("iqr()", "InterquartileRange",features_names$V2)
features_names$V2 <- gsub("entropy()", "SignalEntropy",features_names$V2)
features_names$V2 <- gsub("arCoeff()", "AutorregresionCoefficientsBurgOrder4",features_names$V2)
features_names$V2 <- gsub("correlation()","CorrelationCoefficientBetween2Signals",features_names$V2)
features_names$V2 <- gsub("maxInds()","LargestMagnitudeIndexFrecuencyComponent",features_names$V2)
features_names$V2 <- gsub("meanFreq()","WeightedAverageFrequencyToObtainMeanFrequency",features_names$V2)
features_names$V2 <- gsub("skewness()", "FrecuencyDomainSignalSkewness",features_names$V2)
features_names$V2 <- gsub("kurtosis()", "FrecuencyDomainSignalKurtosis",features_names$V2)
features_names$V2 <- gsub("bandsEnergy()", "FrecuencyIntervalEnergy64binsFFT",features_names$V2)
features_names$V2 <- gsub("angle()", "AngleBetweenVectors",features_names$V2)
View(features_names)
features_names <- read.table("UCI HAR Dataset/features.txt", header = F)
activity_levels <- read.table("UCI HAR Dataset/activity_labels.txt", header = F)
features_names$V2[516:554]
View(activity_levels)
